{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'humpy': 1, 'dumpty': 1, Ellipsis: 1, 'together': 1, 'again': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = ['humpy', 'dumpty', ... , 'together', 'again']\n",
    "counts = Counter(words)\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ellipsis,\n",
       " Ellipsis,\n",
       " 'humpy',\n",
       " 'dumpty',\n",
       " 'together',\n",
       " 'humpy',\n",
       " 'together',\n",
       " 'again',\n",
       " 'together',\n",
       " 'dumpty']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choices(list(counts.keys()), weights=list(counts.values()), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = [(words[i], words[i + 1]) for i in range(len(words) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('humpy', 'dumpty'), ('dumpty', Ellipsis), (Ellipsis, 'together'), ('together', 'again')]\n"
     ]
    }
   ],
   "source": [
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bigram Model.\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def compute_bigram_model(path, files):\n",
    "    \"\"\"Compute a bigram model for a given corpus, including unigram probabilities.\n",
    "\n",
    "    Params\n",
    "    ======\n",
    "        path: directory where input files are located\n",
    "        files: list of files, or a single string specifying regex pattern to match (e.g. r'.*\\.txt')\n",
    "\n",
    "    Returns\n",
    "    =======\n",
    "        p_unigrams: dict with frequency of single words (need not be normalized to [0, 1])\n",
    "        p_bigrams: dict of dicts with frequency of bigrams (need not be normalized to [0, 1])\n",
    "\n",
    "    \"\"\"\n",
    "    p_unigrams = dict()\n",
    "    p_bigrams = dict() \n",
    "    \n",
    "    # Grab a list of all files in specified corpus\n",
    "    if isinstance(files, str):\n",
    "        files = [f for f in os.listdir(path) if re.match(files, f)]  # collect all matching filenames\n",
    "    files = [os.path.join(path, f) for f in files]  # prepend path to each filename\n",
    "\n",
    "    # TODO: Read in text from each file and combine into a single string\n",
    "    text = str()\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            text += f.read()\n",
    "\n",
    "    # TODO: Clean and tokenize text (note that you may want to retain case and sentence delimiters)\n",
    "    print(text[:100])\n",
    "    delimiters = \"...\", \".\", \",\", \"\\n\", \";\", \"?\", \" \", \"'\", \"[\", \"]\"\n",
    "    regexPattern = '|'.join(map(re.escape, delimiters)) \n",
    "    tokenized_text = re.split(regexPattern, text)\n",
    "    words = [text for text in tokenized_text if text is not \"\"]\n",
    "    print(words[:100])\n",
    "\n",
    "    # TODO: Compute unigram probabilities\n",
    "    # P( wi ) = count ( wi ) ) / count ( total number of words )\n",
    "    total_number_of_tokens = len(words)\n",
    "    word_occurences = Counter(words)\n",
    "    print (\"occurrences of word 'Alice' is\", word_occurences['Alice'])\n",
    "    \n",
    "    for word in word_occurences:\n",
    "        p_unigrams[word] = word_occurences[word] / total_number_of_tokens\n",
    "    print (\"unigram % of word 'Alice' is\", p_unigrams['Alice'])  \n",
    "    \n",
    "\n",
    "    # TODO: Compute bigram probabilities\n",
    "    # P( wi | wi-1 ) = count ( wi-1, wi ) / count ( wi-1 )\n",
    "    # Probability that wordi-1 is followed by wordi = [Num times we saw wordi-1 \n",
    "    # followed by wordi] / [Num times we saw wordi-1]\n",
    "    \n",
    "    # 1 - You can find pairs of consecutive words using a list comprehension such as:\n",
    "    bigrams = [(words[i], words[i + 1]) for i in range(len(words) - 1)]\n",
    "    bigram_occurences = Counter(bigrams)\n",
    "    \n",
    "    for bigram in bigram_occurences:\n",
    "        first_word = str(bigram[0])\n",
    "        second_word = str(bigram[1])\n",
    "        first_word_occurences = word_occurences[first_word]\n",
    "        p = bigram_occurences[bigram] / first_word_occurences\n",
    "        \n",
    "        if first_word in p_bigrams.keys():\n",
    "            probability = p_bigrams[first_word]\n",
    "            probability[second_word] = p\n",
    "            p_bigrams[first_word] = probability\n",
    "        else:  \n",
    "            probability = dict()\n",
    "            probability[second_word] = p\n",
    "            p_bigrams[first_word] = probability\n",
    "            \n",
    "        \n",
    "    # print (p_bigrams['Alice'])\n",
    "\n",
    "    return p_unigrams, p_bigrams\n",
    "\n",
    "\n",
    "def generate_sequence(p_unigrams, p_bigrams, num_words=100, seed_word=None):\n",
    "    \"\"\"Generate a random sequence of words, given unigram and bigram probabilities.\"\"\"\n",
    "\n",
    "    # If seed_word is not given, pick one randomly based on unigram probabilities\n",
    "    if seed_word is None:\n",
    "        seed_word = random.choices(list(p_unigrams.keys()), weights=list(p_unigrams.values()))[0]\n",
    "    seq = [seed_word]\n",
    "    for i in range(num_words):\n",
    "        seq.append(random.choices(list(p_bigrams[seq[-1]].keys()), weights=list(p_bigrams[seq[-1]].values()))[0])\n",
    "    return seq\n",
    "\n",
    "\n",
    "def test_run():\n",
    "    # Compute bigram model\n",
    "    p_unigrams, p_bigrams = compute_bigram_model(path='.', files=['carroll-alice.txt'])\n",
    "\n",
    "    # Check most common unigrams (single words)\n",
    "    print(\"10 most common unigrams:\")\n",
    "    sorted_unigrams = sorted(p_unigrams.items(), key=lambda item: item[1], reverse=True)  # each item = (i, count)\n",
    "    for word, count in sorted_unigrams[:10]:\n",
    "        print(\"{}\\t{}\".format(word, count))\n",
    "\n",
    "    # Check most common bigrams (pairs of words)\n",
    "    all_bigrams = [(i, j, count) for i in p_bigrams.keys() for j, count in p_bigrams[i].items()]\n",
    "    sorted_bigrams = sorted(all_bigrams, key=lambda item: item[2], reverse=True)  # each item = (i, j, count)\n",
    "    print(\"10 most common bigrams:\")\n",
    "    for i, j, count in sorted_bigrams[:10]:\n",
    "        print(\"{}\\t{}\\t{}\".format(i, j, count))\n",
    "\n",
    "    # Generate a sample sequence of words\n",
    "    seq = generate_sequence(p_unigrams, p_bigrams, seed_word=\"Alice\")\n",
    "    print(\" \".join(seq))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was\n",
      "['Alice', 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', 'CHAPTER', 'I', 'Down', 'the', 'Rabbit-Hole', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', 'and', 'of', 'having', 'nothing', 'to', 'do:', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', 'thought', 'Alice', 'without', 'pictures', 'or', 'conversation', 'So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(as', 'well', 'as', 'she', 'could', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid)', 'whether', 'the', 'pleasure', 'of', 'making']\n",
      "occurrences of word 'Alice' is 379\n",
      "unigram % of word 'Alice' is 0.013951262607671353\n",
      "10 most common unigrams:\n",
      "the\t0.05569461827284105\n",
      "and\t0.028417875285283074\n",
      "to\t0.026356475005521608\n",
      "a\t0.022380917323124493\n",
      "I\t0.019104763307075022\n",
      "she\t0.018258116763601562\n",
      "it\t0.018221306044320106\n",
      "of\t0.01818449532503865\n",
      "said\t0.01656482367665464\n",
      "Alice\t0.013951262607671353\n",
      "10 most common bigrams:\n",
      "Lewis\tCarroll\t1.0\n",
      "Carroll\t1865\t1.0\n",
      "1865\tCHAPTER\t1.0\n",
      "Rabbit-Hole\tAlice\t1.0\n",
      "do:\tonce\t1.0\n",
      "conversations\tin\t1.0\n",
      "stupid)\twhether\t1.0\n",
      "daisy-chain\twould\t1.0\n",
      "daisies\twhen\t1.0\n",
      "pink\teyes\t1.0\n",
      "Alice said after a great relief Call the Duchess! Oh my youth as if she could not as sure what Alice and then the Dodo a good deal frightened to see what to do \" Oh my throat! and four times since she was shrinking rapidly: she looked down on the young Crab took them back in The miserable Hatter and after a sad tale! said turning purple I grow up and she came skimming out the Queen was all comfortable and more simply--\"Never imagine yourself some attempts at Alice seriously I can find them to feel with the edge of\n"
     ]
    }
   ],
   "source": [
    "test_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
